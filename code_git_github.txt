from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg

# Initialize a Spark session
spark = SparkSession.builder.appName("Example").getOrCreate()

# Sample data
data = [
    (1, "Alice", 25, 50000, "HR"),
    (2, "Bob", 35, 60000, "IT"),
    (3, "Charlie", 28, 70000, "IT"),
    (4, "David", 40, 80000, "Finance"),
    (5, "Eve", 32, 90000, "HR"),
    (6, "Frank", 29, 120000, "Finance"),
    (7, "Grace", 50, 100000, "IT")
]

# Create DataFrame
df = spark.createDataFrame(data, ["id", "name", "age", "salary", "department"])

# Filter out records where age is less than 30
filtered_df = df.filter(col("age") >= 30)

# Group by department and calculate the average salary
result_df = filtered_df.groupBy("department").agg(avg("salary").alias("average_salary"))

# Show the result
result_df.show()

=====================

from pyspark.sql import SparkSession,Row
spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()

data = [("James","Sales",3000),("Michael","Sales",4600),
      ("Robert","Sales",4100),("Maria","Finance",3000),
      ("Raman","Finance",3000),("Scott","Finance",3300),
      ("Jen","Finance",3900),("Jeff","Marketing",3000),
      ("Kumar","Marketing",2000)]

df = spark.createDataFrame(data,["Name","Department","Salary"])
df.show()
df,printschema()